{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b23e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/patrick/anaconda3/lib/python3.9/site-packages (0.24.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7 MB 175 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/patrick/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/patrick/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/patrick/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/patrick/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.20.3)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "Successfully installed scikit-learn-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8a87144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.feature_extraction.text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords, words\n",
    "import nltk\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "208c8407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.distutils.misc_util.Configuration"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a9cc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/patrick/Solen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4622edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Restaurant_Reviews.tsv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path+'/Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c4b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'/Data/Restaurant_Reviews.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "351d1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/patrick/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "61660f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "def remove_stopwords(s):\n",
    "    s2 = [w for w in s.split(' ') if w not in stopwords.words('english')]\n",
    "    return ' '.join(s2)\n",
    "\n",
    "def remove_misspells(s):\n",
    "    s2 = [w for w in s.split(' ') if w in words.words()]\n",
    "    return ' '.join(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b62adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = df.Review.str.lower().replace('[^a-z ]','',regex=True)\n",
    "rev = rev.map(remove_stopwords)\n",
    "rev = rev.map(remove_misspells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7cf0d3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              wow place\n",
       "1                                             crust good\n",
       "2                                    tasty texture nasty\n",
       "3      stopped late may bank holiday rick recommendation\n",
       "4                                   selection menu great\n",
       "                             ...                        \n",
       "995                            think food flavor texture\n",
       "996                              appetite instantly gone\n",
       "997                                overall would go back\n",
       "998             whole experience think well go next time\n",
       "999    wasted enough life salt wound drawing time too...\n",
       "Name: Review, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf9546a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "cv = CountVectorizer(tokenizer=stemming_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a79ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_cv = cv.fit_transform(list(rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "35b61b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "79b0de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_fit = lda.fit_transform(rev_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d417bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  ['place', 'restaur', 'eat', 'pretti', 'would', 'realli', 'love', 'pizza', 'amaz', 'great']\n",
      "Topic 1:  ['like', 'food', 'also', 'best', 'ever', 'tast', 'got', 'could', 'better', 'get']\n",
      "Topic 2:  ['food', 'servic', 'good', 'back', 'go', 'great', 'time', 'disappoint', 'delici', 'dont']\n"
     ]
    }
   ],
   "source": [
    "# Print the topics with their terms\n",
    "terms = cv.get_feature_names()\n",
    "\n",
    "for index, component in enumerate(lda.components_):\n",
    "    zipped = zip(terms, component)\n",
    "    top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:10]\n",
    "    top_terms_list=list(dict(top_terms_key).keys())\n",
    "    print(\"Topic \"+str(index)+\": \",top_terms_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
